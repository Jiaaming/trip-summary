---
id: aws-intern-takeaway
title: AWS SDE实习心得，技术之外的收获
date: 2025-09-12
tags:
  - 技术

category: posts

---


![](https://raw.githubusercontent.com/Jiaaming/blogImage/main/pic/BAFC57A2-C3DD-4816-8C19-F67AB17D07E3_1_105_c.jpeg)


夏天真是过得飞快，在温哥华AWS的这四个月，可以说是我人生中最难忘最充实的夏天了。除了温哥华美好的气候，实习做的项目让我感到了极大的挑战和满足感，加上全组超赞的工作氛围，简直是顶级的实习体验。

这篇博客不是一篇典型的技术分享，我不会（~~也不能~~）讨论具体的技术解法，而是想聚焦在整个实习过程中的收获和一些被inspire的地方，聊一聊我作为一个intern，在面对庞大复杂的工程系统时的体会和思考。

---
![](https://raw.githubusercontent.com/Jiaaming/blogImage/main/pic/7E979352-C92D-45BB-B528-974145ED6747_1_105_c.jpeg)

我的组叫Ingestion hub，主要维护一个叫 [vended log](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AWS-logs-and-resource-policy.html) 的服务。简单来说，就是当用户订阅了某个AWS云服务后，可以设置将产生的log发送到其他的账户。本质上是信息的传输和分发，而主要的挑战在于，如何通过一个极其庞大和复杂的infra，高效稳定地处理和转发这些日志信息。

我负责优化的是一个非常具体但又关键的问题：当某个用户突然发送超大量的log，比如瞬间产生十倍于平时的流量时，系统中的某个模块会“过载”（overload），进而影响整个系统的稳定性。我的任务就是设计并实现一套自动化的“搁置”（sideline）机制来应对这种情况。

听起来思路很直接，但当真正开始设计时，一连串的问题就浮现了：

*   **如何定义“过载”？** 监控系统的哪些指标（CPU？内存？队列长度？）才能准确判断？如何避免“假阳性”（false positive）？
*   **用什么算法来监测？** 是监测数据的体积（byte size）还是速率（TPS）？如何确保算法在各种边缘情况下依然有效？
*   **“搁置”后如何重启？** 如何设计一个优雅的重启机制，确保这些被搁置的数据能被重新处理，同时又不与正常的或出错的数据混淆？
*   **如何确保整个过程的高效和稳定？** 搁置和重启本身不能成为新的性能瓶颈，也不能引入新的bug。

---
![](https://raw.githubusercontent.com/Jiaaming/blogImage/main/pic/66226CAB-2CB3-498D-BDA0-BC60FB20F4AE_1_105_c.jpeg)

入职第一天，我的mentor就很坦诚地告诉我，这个项目难度不小，如果能独立完成，至少是L5的水平（NG升一级）。后来第一次跟mgr 1 on 1，她甚至在安慰我：“没关系，我们发return offer时会充分参考项目难度的。” 这让我既感到压力山大又莫名兴奋。

幸运的是，整个组都非常supportive。我的mentor在前两周，每天都会雷打不动地跟我进行一小时的1 on 1，帮我梳理系统、解答疑惑。

尽管如此，面对系统的客观复杂性，我前几周依然是“懵逼”状态。我要处理的部分（scope）大概只占整个系统的10%，但为了理解这10%，我必须对剩下90%的上下文有所了解。一开始，我只能把我接收到的信息和我读到的代码，以一种低维、简化的方式当成“定义”来强行理解，但这种“定义”往往是不准确甚至错误的。并且由于理解上的差异，在这个阶段是很难跟懂这个系统的人进行“对齐”的（原谅我用这么阿里味的词但是真的用在这里好合适...），双方只能在理解程度接近的时候沟通才比较有效。    
比如我个人体验也是在第四周进行Design Doc review的时候我是真的完全不懂组里L7问的问题，但是在实习结尾demo的时候已经能像样的讨论了。

![](https://raw.githubusercontent.com/Jiaaming/blogImage/main/pic/8A74D6F3-362C-415F-AAFF-0ED1C6E97452_1_105_c.jpeg)


Mentor教了我一个非常有效的方法：**带着假设去读代码**。先通过文档和架构图，在脑海里形成一个关于系统如何工作的初步模型，然后带着这个模型去代码里寻找证据，验证或推翻自己的假设，把被动的“阅读”变成了主动的“侦探游戏”，还是挺有效的。

这个过程也让我深刻体会到工程实践和学生时代学习的巨大差异。中学学数学，任何公式和定理都可以一路推导到最底层的公理（比如1+1=2这种级别），知识体系里不存在无法解释的“GAP”。但在大型软件工程中，你不可能懂得所有细节。**每个工程师都只能在某一个抽象层停下，信任下一层的抽象是可靠的。** 你没法像在学校里那样，先把所有知识点过一遍再动手，唯一的路径就是一边做一边学，一边学一边做。

比方说造飞机，工程师需要懂空气动力学、材料学和发动机原理，但并不需要从牛顿定律和元素周期表开始推导。他在一个已经构建好的抽象层上工作，并相信底层的物理规律是坚实的。工程师的工作也是在这些复杂的抽象层之间，搭建新的桥梁。

实习过半，当我基本完成核心功能后，再回过头去大量阅读代码和文档，才感觉自己真正称得上是理解了我负责的那部分需要的抽象。组里讨论现有系统问题时我也终于能听懂部分了。这种“量变引起质变”的体验真的非常奇妙。

---
![](https://raw.githubusercontent.com/Jiaaming/blogImage/main/pic/7573A8B5-1D1A-474C-8F86-5DBE79F60B4E_1_105_c.jpeg)  

有别于很多intern直接根据mentor的design来实现，我的mentor和全组都非常鼓励我去独立思考和设计。Mentor尤其注重训练我对项目逻辑的理解：我们为什么要这样设计？背后最根本的原因（root cause）是什么？

实习生项目的设计，组里通常已经有了初步的方案。我一开始就拿到了一个设计文档的草稿——这相当于是直接给了我部分结论。如果我没有主动去思考“为什么是这个结论”，只是一个劲地往下实现，就很容易在细节上“跑偏”（我一开始确实跑偏了）。

这种追问“Why”的能力，也是AWS在复盘重大系统事件（COE）时极其看重的文化。其中最经典的例子就是“林肯纪念碑”的故事（@chatgpt）：

**背景：**
林肯纪念碑的外墙石材出现了严重的老化和侵蚀。管理方的第一反应是：花大钱更换更耐用的石材或加强修缮。

但通过一层层地问“Why”，他们挖出了问题的根源：

*   **为什么纪念碑的石材会老化严重？**
    → 因为建筑表面经常被强力清洗剂冲洗。
*   **为什么要这么频繁地清洗？**
    → 因为墙上有很多鸟粪，影响美观。
*   **为什么这里有这么多鸟？**
    → 因为纪念碑周围聚集了大量的蜘蛛，是鸟的美餐。
*   **为什么有这么多蜘蛛？**
    → 因为晚上有很多飞蛾和昆虫在这里聚集。
*   **为什么有这么多昆虫？**
    → 因为纪念碑的夜间照明系统在黄昏时就早早开启，强光吸引了它们。

**最终结论：**
石材老化的根本原因，是**开灯时间太早**。

**解决方案：**
不是花巨资换石材，而是调整照明策略——将开灯时间推迟一小时。昆虫减少了，蜘蛛和鸟类也就随之减少，清洗频率大大降低，纪念碑的石材得到了保护。

这个故事给了我很大的启发。当我在实习中遇到问题无法unblock myself，向组里有经验的工程师请教时，我能非常深刻地感受到他们身上这种追本溯源的mindset。他们不会直接给我一个答案，而是会反问我几个问题，引导我自己找到问题的核心。这也是我需要在后续锻炼的。
